---
title: "October 26"
output: 
  bookdown::pdf_document2:
    number_sections: false
    toc: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE, cache = TRUE, dev = "ragg_png", dpi=200)
library(tidyverse)
library(targets)
library(effectsize)
library(patchwork)

source(here::here("R", "updates.R"))
Sys.setenv(TAR_PROJECT = "ale")
tar_config_set(store = here::here("_ale"))

J <- function(N) gamma((N-1)/2) / (sqrt((N-1)/2) * gamma((N-2)/2))
```

```{r, data}

tar_load(comparison)
tar_load(z_pop)
tar_load(ibma_summary)

mask_nii <- fslr::mni_img(mm="2", mask=TRUE, brain=TRUE) 

pop <- neurobase::img_indices(z_pop, mask=mask_nii, add_values = TRUE) |>
  as_tibble() |>
  rename(pop = value) |>
  mutate(pop = 2 * pop / sqrt(900))

seg <- neurobase::img_indices(MNITemplate::readMNISeg(res="2mm"), add_values=TRUE) |>
  as_tibble() |>
  filter(value == 2) |>
  select(-value)

tmp <- comparison  |>
  semi_join(seg, by = c("x","y","z")) |>
  rename(Z=t)

# ibma
ibma <- ibma_summary |>
  mutate(
    N = n_study * n_sub,
    value = value / sqrt(N) * 2)

```

## UK Biobank

### Oracle Grant

You saw that the grant was funded. I think this will be a fun project, A couple of closely related reports came out recently (Dadi et al. 2021 https://doi.org/10.1093/gigascience/giab071; DockÃ¨s et al. 2021 https://doi.org/10.1093/gigascience/giab055. 

### Meta Analysis / Effect Size

I'm hoping to talk through a potential way to refocus these simulations. When we last met, we spent a while discussing how to report an effect size in for the coordinate-based meta-analysis. Since then, my main goal was to revisit the literature to see if there were strategies for a straight calculation of effect size from a coordinate-based meta-analysis. While I've seen a few techniques for mixing coordinate- and image-based meta-analyses, partly to estimate effect sizes, I'm still not aware of a method for extracting effect sizes from ALE alone using a published method. I'm a bit wary of this project being too much about the different ways of performing ALE, crossed with the different ways of combining coordinate- and image-based meta-analyses. I was hoping to talk through a few approaches for linking these meta-analysis studies back to the point about larger datasets producing smaller but more reliable effects. 

#### Coordinate-Based

```{r, zbyd, fig.cap="Relationship between ALE z-statistic and gold standard Cohen's d. Points correspond to voxels within a gray matter mask. Only voxels with positive Cohen's d are shown. Solid line has unit slope and intercept 0.", fig.height=4, fig.width=4}
tmp |>
  filter(Z > 0) |>
  group_by(n_sub, n_study, x, y, z) |>
  summarise(Z = mean(Z), .groups = "drop") |>
  left_join(pop, by = c("x","y","z")) |>
  filter(pop > 0) |>
  ggplot(aes(x = pop, y = Z)) +
  facet_grid(n_sub ~ n_study, labeller = label_both) +
  geom_abline(slope=1, intercept = 0) +
  geom_point(alpha = .01) +
  # coord_fixed() +
  xlab("Cohen's d (Population)") +
  ylab("z-stat (Meta)")
```


```{r, cbmadice, fig.cap="Spatial Overlap within Gray Matter. In both meta-analyses and gold standard, voxels were thresholded at p < 0.01. Points correspond to separate meta-analysis, five per combination of study and participant counts.", fig.width=3, fig.width=7.5}

thresh <- 0.99

a <- tmp |>
  left_join(pop |> mutate(pop = pop*sqrt(900)), by = c("x","y","z")) |>
  calc_dice_whole(Z, lower = qnorm(thresh)) |>
  ggplot(aes(x=n_study, y=dice)) +
  facet_wrap(~n_sub, labeller = label_both) +
  geom_point(alpha = 0.5) +
  scale_y_continuous(
    name = "Dice Coefficient",
    limits = c(0,0.5))

b <- tmp |>
  left_join(pop |> mutate(pop = pop*sqrt(900)), by = c("x","y","z")) |>
  calc_tpr_whole(Z, lower = qnorm(thresh)) |>
  ggplot(aes(x=n_study, y=dice)) +
  facet_wrap(~n_sub, labeller = label_both) +
  geom_point(alpha = 0.5) +
  scale_y_continuous(
    name = "True Positive Rate",
    limits = c(0, 0.25))

c <- tmp |>
  left_join(pop |> mutate(pop = pop*sqrt(900)), by = c("x","y","z")) |>
  calc_fpr_whole(Z, lower = qnorm(thresh)) |>
  ggplot(aes(x=n_study, y=dice)) +
  facet_wrap(~n_sub, labeller = label_both) +
  geom_point(alpha = 0.5) +
  scale_y_continuous(
    name = "False Positive Rate",
    limits = c(0,0.25))

a | (b + c) + plot_layout(nrow=2)

```


![Coordinate-based vs. Gold Standard. Gold standard z-map shown in blue, thresholded at z>2. Meta-analysis shown in red, without thresholding (30 studies each with 30 participant). By design, ALE finds the peaks, but note that this does not necessarily mean it finds the full extent of a robust cluster (e.g., ventral visual stream). The meta-analysis is masked with a brain mask, but not the gold standard. ](screenshot.png)

#### Image-Based

Cohen's d estimated for gold standard as $\hat{d} = 2*t*\sqrt{900}$, where $t$ is the $t$-statistic calculated from 900 participants. To estimate the beta coefficients for the meta-analysis, an approach from DerSimonian and Laird (1986) that relies on a weighted least squares, which produces a random effects beta coefficient that was converted to an estimate of Cohen's d as in the gold standard ($2*t*\sqrt{nstudy*nsub}$). The meta-analyses are almost accurate, although it looks like there is a slight bias based on the extreme effect sizes (Figure \@ref(fig:ibma)). I'm still looking into the details of this method to understand if a bias is expected with these sample sizes.

```{r, ibma, fig.cap="Example Comparison Between Image-Based Meta-Analysis and Population Gold Standard. Each panel reflects a single simulated meta-analysis, with points indicating gray matter voxels.", fig.width=7, fig.height=6}

# p <- tmp |>
#   filter(Z > 0) |>
#   group_by(n_sub, n_study, x, y, z) |>
#   summarise(d = mean(d), .groups = "drop") |>
#   left_join(pop, by = c("x","y","z")) |>
#   filter(pop > 0) |>
#   ggplot(aes(x = pop, y = d)) +
#   facet_grid(n_sub ~ n_study, labeller = label_both) +
#   geom_abline(slope=1, intercept = 0) +
#   geom_point(alpha = .01) +
#   # coord_fixed() +
#   xlab("Cohen's d (Population)") +
#   ylab("z-stat / sqrt(n) (Meta)")

# ggsave("tmp3.png", p, device = ragg::agg_png)


# p2 <- tmp |>
#   filter(pop > 0) |>
#   group_by(n_sub, n_study, x, y, z) |>
#   summarise(Z = mean(Z), p = mean(p), stat=mean(stat), .groups = "drop") |>
#   mutate(pop = pop / sqrt(n_study)) |>
#   left_join(ibma, by = c("x", "y", "z")) |>
#   ggplot(aes(x = pop, y = value)) +
#   facet_grid(n_sub ~ n_study, labeller = label_both) +
#   geom_point(alpha = .01) +
#   coord_fixed() +
#   xlab("Cohen's d (Population)") +
# #   ylab("Cohen's d (IB Meta)")

ibma |>
  left_join(pop, by = c("x", "y", "z")) |>
  ggplot(aes(x = pop, y = value)) +
  facet_grid(n_sub ~ n_study, labeller = label_both) +
  geom_point(alpha = .01) +
  geom_abline(slope=1, intercept = 0) +
  coord_fixed() +
  xlab("Cohen's d (Population; MFX)") +
  ylab("Cohen's d (IB Meta; MFX)")

```
